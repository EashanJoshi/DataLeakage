{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import nbformat\n",
        "import ast\n",
        "\n",
        "# ---- STEP 1: Extract Code from Jupyter Notebook ---- #\n",
        "def extract_code_from_notebook(notebook_path, output_script_path=\"extracted_script.py\"):\n",
        "    \"\"\"Extracts Python code from an .ipynb notebook and saves it as a .py script.\"\"\"\n",
        "    with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        notebook = nbformat.read(f, as_version=4)\n",
        "\n",
        "    code_cells = [cell[\"source\"] for cell in notebook.cells if cell[\"cell_type\"] == \"code\"]\n",
        "    extracted_code = \"\\n\\n\".join(code_cells)\n",
        "\n",
        "    with open(output_script_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(extracted_code)\n",
        "\n",
        "    print(f\"Code extracted and saved to {output_script_path}\")\n",
        "    return extracted_code\n",
        "\n",
        "# ---- STEP 2: Static Analysis for Data Leakage ---- #\n",
        "class LeakageAnalyzer(ast.NodeVisitor):\n",
        "    \"\"\"Analyzes Python code for data leakage risks.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.transformed_vars = set()\n",
        "        self.split_vars = set()\n",
        "        self.test_vars = set()\n",
        "        self.leakage_warnings = {\"Preprocessing Leakage\": [], \"Overlap Leakage\": [], \"Multi-Test Leakage\": []}\n",
        "\n",
        "    def visit_Assign(self, node):\n",
        "        \"\"\"Detects fit_transform() or fit_resample() and tracks assigned variables.\"\"\"\n",
        "        if isinstance(node.value, ast.Call) and hasattr(node.value.func, \"attr\"):\n",
        "            function_name = node.value.func.attr\n",
        "\n",
        "            if function_name in [\"fit_transform\", \"fit_resample\"]:\n",
        "                if isinstance(node.targets[0], ast.Name):\n",
        "                    transformed_var = node.targets[0].id\n",
        "                    self.transformed_vars.add(transformed_var)\n",
        "                    self.leakage_warnings[\"Preprocessing Leakage\"].append(\n",
        "                        f\"{function_name} used on {transformed_var} at line {node.lineno}\"\n",
        "                    )\n",
        "\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def visit_Call(self, node):\n",
        "        \"\"\"Detects train_test_split(), pd.concat(), and model.score()\"\"\"\n",
        "        if hasattr(node.func, \"attr\"):\n",
        "            function_name = node.func.attr\n",
        "\n",
        "            if function_name == \"train_test_split\":\n",
        "                for arg in node.args:\n",
        "                    if isinstance(arg, ast.Name):\n",
        "                        self.split_vars.add(arg.id)\n",
        "\n",
        "            if function_name == \"concat\":\n",
        "                self.leakage_warnings[\"Overlap Leakage\"].append(\n",
        "                    f\"pd.concat() used before splitting at line {node.lineno}\"\n",
        "                )\n",
        "\n",
        "            if function_name == \"score\":\n",
        "                for arg in node.args:\n",
        "                    if isinstance(arg, ast.Name):\n",
        "                        if arg.id in self.test_vars:\n",
        "                            self.leakage_warnings[\"Multi-Test Leakage\"].append(\n",
        "                                f\"Multiple evaluations on {arg.id} at line {node.lineno}\"\n",
        "                            )\n",
        "                        self.test_vars.add(arg.id)\n",
        "\n",
        "        self.generic_visit(node)\n",
        "\n",
        "    def check_for_preprocessing_leakage(self):\n",
        "        \"\"\"Confirm preprocessing leakage only if transformed variables are used in train_test_split.\"\"\"\n",
        "        for var in self.transformed_vars:\n",
        "            if var in self.split_vars:\n",
        "                self.leakage_warnings[\"Preprocessing Leakage\"].append(\n",
        "                    f\"Confirmed: {var} transformed before train-test split\"\n",
        "                )\n",
        "\n",
        "# ---- STEP 3: Run the Full Process ---- #\n",
        "def analyze_code_for_leakage(code):\n",
        "    \"\"\"Runs the static analysis for detecting data leakage in Python code.\"\"\"\n",
        "    tree = ast.parse(code)\n",
        "    analyzer = LeakageAnalyzer()\n",
        "    analyzer.visit(tree)\n",
        "    analyzer.check_for_preprocessing_leakage()\n",
        "\n",
        "    print(\"\\nAnalyzing Code for Data Leakage...\\n\")\n",
        "    issues_found = sum(len(w) for w in analyzer.leakage_warnings.values())\n",
        "\n",
        "    for category, warnings in analyzer.leakage_warnings.items():\n",
        "        if warnings:\n",
        "            print(f\"{category}:\")\n",
        "            for warning in warnings:\n",
        "                print(f\"  - {warning}\")\n",
        "\n",
        "    if issues_found == 0:\n",
        "        print(\"\\nNo obvious data leakage detected\")\n",
        "    else:\n",
        "        print(f\"\\nAnalysis complete: {issues_found} issue(s) found\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    notebook_path = \"titanic-advanced-feature-engineering-tutorial.ipynb\"\n",
        "\n",
        "    extracted_code = extract_code_from_notebook(notebook_path, \"extracted_script.py\")\n",
        "    analyze_code_for_leakage(extracted_code)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS9RtsgqZt6Z",
        "outputId": "c665b898-41b9-484a-ed17-8e2de12dbb76"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Code extracted and saved to extracted_script.py\n",
            "\n",
            "Analyzing Code for Data Leakage...\n",
            "\n",
            "Preprocessing Leakage:\n",
            "  - fit_transform used on X_train at line 552\n",
            "  - fit_transform used on X_test at line 554\n",
            "Overlap Leakage:\n",
            "  - pd.concat() used before splitting at line 21\n",
            "  - pd.concat() used before splitting at line 540\n",
            "  - pd.concat() used before splitting at line 541\n",
            "\n",
            "Analysis complete: 5 issue(s) found\n"
          ]
        }
      ]
    }
  ]
}